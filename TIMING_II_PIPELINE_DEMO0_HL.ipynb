{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIMING II Pipeline Demo\n",
    "Welcome to TIMING II Pipeline!  This notebook will walk you step by step through the whole TIMING Pipeline, which includes the nanowell detection, cell segmentationa, tracking and feature calculation. The visualization module works independently from another terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORE_NUMBER = 12   #Multi-core speed up setting\n",
    "\n",
    "TIMING_II_HOME = 'E:\\\\TIMING\\\\TIMING2\\\\'\n",
    "\n",
    "############################################## Don't Modify below in this code cell ################################### \n",
    "# This is needed for nanowell detection.\n",
    "sys.path.append(TIMING_II_HOME + 'timing2-preprocessing\\\\')\n",
    "\n",
    "# This is needed for nanowell detection.\n",
    "sys.path.append(TIMING_II_HOME + 'timing2-crop\\\\faster-rcnn\\\\')\n",
    "\n",
    "# This is needed for nanowell cropping.\n",
    "sys.path.append(TIMING_II_HOME + 'timing2-crop\\\\')\n",
    "\n",
    "# This is needed for segmentation modules\n",
    "sys.path.append(TIMING_II_HOME + 'timing2-seg\\\\')\n",
    "\n",
    "# This is needed for Cell Tracking.\n",
    "sys.path.append(TIMING_II_HOME + 'timing2-tracker\\\\')\n",
    "\n",
    "# This is needed for Utility functions.\n",
    "sys.path.append(TIMING_II_HOME + 'timing2-utils\\\\')\n",
    "\n",
    "# This is needed for feature calculation modules\n",
    "sys.path.append(TIMING_II_HOME + 'timing2-features\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIMING II Parameter Configuration\n",
    "Set up the parameters below before running the process for a batch of input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Part 1: Dataset Parameters\n",
    "Dataset_Name = '20180223_MM_02_ctrl'\n",
    "Data_Raw_DIR = 'E:\\\\TIMING\\\\TIMING2_Datasets_Raw'\n",
    "Data_DIR = 'E:\\\\TIMING\\\\TIMING2_Benchmark_Datasets'\n",
    "\n",
    "Dataset_Input = 'IN'\n",
    "Dataset_Output = 'OUT'\n",
    "\n",
    "Dataset_Blocks = ['B'+str(i).zfill(3) for i in range(1,11)]\n",
    "Dataset_Channels = ['CH0','CH1','CH2','CH3']                     # Channels in the experiment, don't need to be changed\n",
    "Dataset_Frames = 73\n",
    "Block_Size = 2048 #pixels\n",
    "Nanowell_Size = 281 #pixels\n",
    "\n",
    "### Part 2: Preprocessing Parameters\n",
    "stack_tuple = (\"bright_field\",\"effectors\",\"targets\",\"death\")     # channels that are stacked together\n",
    "\n",
    "unmix_tuple = (\"targets\",\"effectors\", \"death\") # channels that are used in unmixing  \n",
    "unmix_tuple_clean = (\"targets\", \"effectors\")   # if channels in this tuple, preprocessor will look for umx_Bxxx\n",
    "unmix_ratio_c2_c3 = 0.77                        # otherwise, will use Bxxx to generate new bg_Bxxx    \n",
    "unmix_ratio_c3_c4 = 0.22\n",
    "\n",
    "enhance_tuple = (\"targets\",)\n",
    "min_pixel_value = 0\n",
    "max_pixel_value = 2000\n",
    "\n",
    "preprocess_tuple = (\"effectors\",\"targets\")      # channels that have umx and back ground subtraction\n",
    "\n",
    "channel_dict = {\"bright_field\":\"c1_ORG\",\n",
    "                \"effectors\":\"c4_ORG\",\n",
    "                \"targets\":\"c3_ORG\",\n",
    "                \"death\":\"c2_ORG\",\n",
    "                \"beads_1\":\"--\",\n",
    "                \"beads_2\":\"--\"}\n",
    "\n",
    "channel_naming_dict = {\"bright_field\":\"0\",\n",
    "                       \"effectors\":\"1\",\n",
    "                       \"targets\":\"2\",\n",
    "                       \"death\":\"3\",\n",
    "                       \"beads_1\":\"4\",\n",
    "                       \"beads_2\":\"5\"}\n",
    "microscope = 'zeiss'\n",
    "\n",
    "\n",
    "### Part 3: Pipeline Parameters\n",
    "\n",
    "# Channels Available\n",
    "Channel_available = ['CH0', 'CH1', 'CH2', 'CH3']      # Available Channels in experiments\n",
    "\n",
    "# Segmentation Radius for Channel 1 and 2\n",
    "R_CH1 = 20   # 23\n",
    "R_CH2 = 21   # 24\n",
    "\n",
    "# Resegmentation Configuration\n",
    "CELL_COUNT_THRESHOLD = 0.8\n",
    "CELL_COUNT_MAX = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIMING II Pipeline Step by Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 0: Make directory for preprocessing, only need to run one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocess_Wrapper import TIMING_Preprocess_Mkdir\n",
    "\n",
    "TIMING_Preprocess_Mkdir(Data_DIR, Dataset_Name, Dataset_Input, Dataset_Output, Dataset_Blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Pre-Processing B001 ......\n",
      "Preprocessing B001 TIME: 156.09792828559875\n",
      "Start Pre-Processing B002 ......\n",
      "Preprocessing B002 TIME: 193.8412435054779\n",
      "Start Pre-Processing B003 ......\n",
      "Preprocessing B003 TIME: 173.13560438156128\n",
      "Start Pre-Processing B004 ......\n",
      "Preprocessing B004 TIME: 159.08847975730896\n",
      "Start Pre-Processing B005 ......\n",
      "Preprocessing B005 TIME: 159.84338092803955\n",
      "Start Pre-Processing B006 ......\n",
      "Preprocessing B006 TIME: 174.72680711746216\n",
      "Start Pre-Processing B007 ......\n",
      "Preprocessing B007 TIME: 171.63900184631348\n",
      "Start Pre-Processing B008 ......\n",
      "Preprocessing B008 TIME: 142.02814960479736\n",
      "Start Pre-Processing B009 ......\n",
      "Preprocessing B009 TIME: 139.22014474868774\n",
      "Start Pre-Processing B010 ......\n",
      "Preprocessing B010 TIME: 164.33618903160095\n"
     ]
    }
   ],
   "source": [
    "### Put all the Preprocessing in a block by block cycle\n",
    "from Preprocess_Wrapper import TIMING_Preprocess_Stack\n",
    "from Preprocess_Wrapper import TIMING_Preprocess_Unmix\n",
    "from Preprocess_Wrapper import TIMING_Preprocess_BackgroundSubtract\n",
    "from Preprocess_Wrapper import TIMING_Preprocess_Enhance\n",
    "\n",
    "\n",
    "for Block in Dataset_Blocks:\n",
    "        t1 = time.time()\n",
    "        \n",
    "        print(\"Start Pre-Processing \" + Block + \" ......\")\n",
    "        \n",
    "        Blocks = [Block]\n",
    "        \n",
    "        # Stack the Images\n",
    "        TIMING_Preprocess_Stack(TIMING_II_HOME, Data_Raw_DIR, Data_DIR, Dataset_Name, Dataset_Input, Dataset_Output, Blocks, stack_tuple, channel_dict, channel_naming_dict, microscope, CORE_NUMBER)\n",
    "\n",
    "        # Unmixing c2_ORG and c3_ORG\n",
    "        TIMING_Preprocess_Unmix(2, 0, unmix_ratio_c2_c3, TIMING_II_HOME, Data_Raw_DIR, Data_DIR, Dataset_Name, Dataset_Input, Dataset_Output, Blocks, unmix_tuple, stack_tuple, channel_dict, channel_naming_dict, CORE_NUMBER)\n",
    "        \n",
    "        #Unmixing c3_ORG and c4_ORG\n",
    "        TIMING_Preprocess_Unmix(0, 1, unmix_ratio_c3_c4, TIMING_II_HOME, Data_Raw_DIR, Data_DIR, Dataset_Name, Dataset_Input, Dataset_Output, Blocks, unmix_tuple, stack_tuple, channel_dict, channel_naming_dict, CORE_NUMBER)\n",
    "        \n",
    "        #Background Subtraction\n",
    "        TIMING_Preprocess_BackgroundSubtract(40, TIMING_II_HOME, Data_Raw_DIR, Data_DIR, Dataset_Name, Dataset_Input, Dataset_Output, Blocks, preprocess_tuple, stack_tuple, unmix_tuple_clean, channel_dict, channel_naming_dict, CORE_NUMBER)\n",
    "        \n",
    "        #Channel Enhancement\n",
    "        TIMING_Preprocess_Enhance(min_pixel_value, max_pixel_value,TIMING_II_HOME, Data_Raw_DIR, Data_DIR, Dataset_Name, Dataset_Input, Dataset_Output, Blocks, enhance_tuple, channel_dict, channel_naming_dict, CORE_NUMBER)\n",
    "        \n",
    "        print(\"Preprocessing \" + Block +\" TIME: \" +str(time.time() - t1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Stack the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Preprocess_Wrapper import TIMING_Preprocess_Stack\n",
    "\n",
    "# t1 = time.time()\n",
    "\n",
    "# TIMING_Preprocess_Stack(TIMING_II_HOME, Data_Raw_DIR, Data_DIR, Dataset_Name, Dataset_Input, Dataset_Output, Dataset_Blocks, stack_tuple, channel_dict, channel_naming_dict, microscope, CORE_NUMBER)\n",
    "\n",
    "# print(\"1-STACK TIME: \" +str(time.time() - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2.1: Unmixing the images, remove c2_ORG from c3_ORG, leaked from unmix_tuple[2] to unmix_tuple[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Preprocess_Wrapper import TIMING_Preprocess_Unmix\n",
    "\n",
    "# t1 = time.time()\n",
    "\n",
    "# TIMING_Preprocess_Unmix(2, 0, unmix_ratio_c2_c3, TIMING_II_HOME, Data_Raw_DIR, Data_DIR, Dataset_Name, Dataset_Input, Dataset_Output, Dataset_Blocks, unmix_tuple, stack_tuple, channel_dict, channel_naming_dict, CORE_NUMBER)\n",
    "\n",
    "# print(\"2.1-UNMIX TIME: \" +str(time.time() - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2.2: Unmixing the images, remove c3_ORG from c4_ORG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Preprocess_Wrapper import TIMING_Preprocess_Unmix\n",
    "\n",
    "# t1 = time.time()\n",
    "\n",
    "# TIMING_Preprocess_Unmix(0, 1, unmix_ratio_c3_c4, TIMING_II_HOME, Data_Raw_DIR, Data_DIR, Dataset_Name, Dataset_Input, Dataset_Output, Dataset_Blocks, unmix_tuple, stack_tuple, channel_dict, channel_naming_dict, CORE_NUMBER)\n",
    "\n",
    "# print(\"2.2-UNMIX TIME: \" +str(time.time() - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Background Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Preprocess_Wrapper import TIMING_Preprocess_BackgroundSubtract\n",
    "\n",
    "# t1 = time.time()\n",
    "\n",
    "# TIMING_Preprocess_BackgroundSubtract(40, TIMING_II_HOME, Data_Raw_DIR, Data_DIR, Dataset_Name, Dataset_Input, Dataset_Output, Dataset_Blocks, preprocess_tuple, stack_tuple, unmix_tuple_clean, channel_dict, channel_naming_dict, CORE_NUMBER)\n",
    "\n",
    "# print(\"3-BS TIME: \" +str(time.time() - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Channel Enhancement because Target Channel Pixel value too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Preprocess_Wrapper import TIMING_Preprocess_Enhance\n",
    "\n",
    "# t1 = time.time()\n",
    "\n",
    "# TIMING_Preprocess_Enhance(min_pixel_value, max_pixel_value,TIMING_II_HOME, Data_Raw_DIR, Data_DIR, Dataset_Name, Dataset_Input, Dataset_Output, Dataset_Blocks, enhance_tuple, channel_dict, channel_naming_dict, CORE_NUMBER)\n",
    "\n",
    "# print(\"4-Channel Enhancement TIME: \" +str(time.time() - t1))            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Do a possible clip Enhancement to Effector Channels if pixel value too noise std > 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_clip_value = 100\n",
    "# max_clip_value = 1000\n",
    "\n",
    "# clip_enhance_tuple = (\"Effectors\",)\n",
    "\n",
    "# from Preprocess_Wrapper2 import TIMING_Preprocess_Clip_Enhance\n",
    "\n",
    "# t1 = time.time()\n",
    "\n",
    "# TIMING_Preprocess_Enhance(min_clip_value, max_clip_value,min_pixel_value, max_pixel_value,TIMING_II_HOME, Data_Raw_DIR, Data_DIR, Dataset_Name, Dataset_Input, Dataset_Output, Dataset_Blocks, clip_enhance_tuple, channel_dict, channel_naming_dict, CORE_NUMBER)\n",
    "\n",
    "# print(\"5-Channel Clip-Enhancement TIME: \" +str(time.time() - t1))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Nanowell Localization, Classification and Cropping\n",
    " We use faster r-cnn to do nanowell localization and identify the empty ones which we will discard automatically. Small image patch will be cropped right after the localization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mamart51\\Anaconda2\\envs\\TIMING2-pipeline\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from uint16 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing B001 ......\n",
      "processing B002 ......\n",
      "processing B003 ......\n",
      "processing B004 ......\n",
      "processing B005 ......\n",
      "processing B006 ......\n",
      "processing B007 ......\n",
      "processing B008 ......\n",
      "processing B009 ......\n",
      "processing B010 ......\n",
      "Processing B001 ......\n",
      "Processing B002 ......\n",
      "Processing B003 ......\n",
      "Processing B004 ......\n",
      "Processing B005 ......\n",
      "Processing B006 ......\n",
      "Processing B007 ......\n",
      "Processing B008 ......\n",
      "Processing B009 ......\n",
      "Processing B010 ......\n",
      "STEP-CROPPING TIME: 1477.6816055774689\n"
     ]
    }
   ],
   "source": [
    "from Crop_Wrapper import TIMING_Crop\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "TIMING_Crop(TIMING_II_HOME, Data_DIR, Dataset_Name, Dataset_Input, Dataset_Output, Dataset_Blocks, Dataset_Frames, Nanowell_Size, Block_Size, Channel_available)\n",
    "\n",
    "print(\"STEP-CROPPING TIME: \" +str(time.time() - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Cell Segmentation \n",
    "We use i-vote to detect the seeds for cell candidates. And we use k-means to extract the foreground of cells from the fluorescent channels(CH1 and CH2). Individual cell bodies are clustered based on their distance from each detected seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing B001 ......\n",
      "Processing B002 ......\n",
      "Processing B003 ......\n",
      "Processing B004 ......\n",
      "Processing B005 ......\n",
      "Processing B006 ......\n",
      "Processing B007 ......\n",
      "Processing B008 ......\n",
      "Processing B009 ......\n",
      "Processing B010 ......\n",
      "Processing B001 ......\n",
      "Processing B002 ......\n",
      "Processing B003 ......\n",
      "Processing B004 ......\n",
      "Processing B005 ......\n",
      "Processing B006 ......\n",
      "Processing B007 ......\n",
      "Processing B008 ......\n",
      "Processing B009 ......\n",
      "Processing B010 ......\n",
      "STEP-CELL SEGMENTATION TIME: 1485.4080126285553\n"
     ]
    }
   ],
   "source": [
    " from Segment_Wrapper import TIMING_Segment\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# TIMING_Segment(TIMING_II_HOME, Data_DIR, Dataset_Name, Dataset_Input, Dataset_Output, Dataset_Blocks, Dataset_Frames, CORE_NUMBER, Nanowell_Size, Block_Size, Channel_available, R_CH1, R_CH2)\n",
    "\n",
    "Thresh_CH1= 0.4    # Needs to specify this threshold value for two channels, the lower the value, the more cell bodies\n",
    "\n",
    "Thresh_CH2= 0.2\n",
    "\n",
    "TIMING_Segment(TIMING_II_HOME, Data_DIR, Dataset_Name, Dataset_Input, Dataset_Output, Dataset_Blocks, Dataset_Frames, CORE_NUMBER, Nanowell_Size, Block_Size, Channel_available, Thresh_CH1, Thresh_CH2, R_CH1, R_CH2)\n",
    "\n",
    "print(\"STEP-CELL SEGMENTATION TIME: \" +str(time.time() - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Confinement-Constrained Cell Resegmentation\n",
    "Assume the numbers of cells detected are constant throughout the whole time line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from Segment_Wrapper2 import TIMING_Segment2\n",
    "9\n",
    "# t1 = time.time()\n",
    "\n",
    "# TIMING_Segment2(TIMING_II_HOME, Data_DIR, Dataset_Name, Dataset_Input, Dataset_Output, Dataset_Blocks, Dataset_Frames, CORE_NUMBER, Nanowell_Size, Block_Size, R_CH1, R_CH2)\n",
    "\n",
    "# print(\"STEP-CELL SEGMENTATION TIME: \" +str(time.time() - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP-CELL RE-SEGMENTATION TIME: 74.13133001327515\n"
     ]
    }
   ],
   "source": [
    "from Resegment_Wrapper import TIMING_Resegment\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "TIMING_Resegment(Data_DIR, Dataset_Name, Dataset_Output, Dataset_Blocks, Dataset_Frames, CORE_NUMBER, CELL_COUNT_THRESHOLD, CELL_COUNT_MAX)\n",
    "\n",
    "print(\"STEP-CELL RE-SEGMENTATION TIME: \" +str(time.time() - t1)) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Cell Tracking\n",
    "Based on the results from cell segmentation. We define the cost functions for cell track assignment with cell center distance measure, cell size difference measure and set distance measure. We try to find the optimal tracking result by minimizing the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP-CELL TRACKING TIME: 10.655818700790405\n"
     ]
    }
   ],
   "source": [
    "from Tracking_Wrapper2 import TIMING_Tracker2\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "TIMING_Tracker2(Data_DIR, Dataset_Name, Dataset_Output, Dataset_Blocks, Dataset_Frames, CORE_NUMBER)\n",
    "\n",
    "print(\"STEP-CELL TRACKING TIME: \" +str(time.time() - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. Cell Feature Calculation\n",
    "We quantify the cells in each identified tracks. For Effector cells in Channel 1, we calculate the centroid position, aspect ratio, speed and death marker level at each time point. For Target cells in Channel 2, we calculate an additional contact ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......\n",
      "STEP-FEATURE CALCULATION TIME: 87.8940544128418\n"
     ]
    }
   ],
   "source": [
    "from Feature_Wrapper import TIMING_Features\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "TIMING_Features(Data_DIR, Dataset_Name, Dataset_Output, Dataset_Blocks, Dataset_Frames, CORE_NUMBER)\n",
    "\n",
    "print(\"STEP-FEATURE CALCULATION TIME: \" +str(time.time() - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
